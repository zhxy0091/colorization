{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-99af92aeba93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorflowUtils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named tensorflow"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import TensorflowUtils as utils\n",
    "import read_data as flowers\n",
    "\n",
    "import datetime\n",
    "import batchReader as dataset\n",
    "from six.moves import xrange\n",
    "import os\n",
    "import glob\n",
    "from scipy import misc\n",
    "from skimage import color\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "tf.flags.DEFINE_integer(\"batch_size\", \"16\", \"batch size for training\")\n",
    "tf.flags.DEFINE_string(\"logs_dir\", \"logs/\", \"path to logs directory\")\n",
    "tf.flags.DEFINE_string(\"data_dir\", \"demo/\", \"path to dataset\")\n",
    "tf.flags.DEFINE_string(\"model_dir\", \"logs/model_heatmap_on_pretrain/\", \"path to model\")\n",
    "tf.flags.DEFINE_float(\"learning_rate\", \"1e-4\", \"Learning rate for Adam Optimizer\")\n",
    "tf.flags.DEFINE_float(\"beta1\", \"0.9\", \"Beta 1 value to use in Adam Optimizer\")\n",
    "tf.flags.DEFINE_string(\"model_dir\", \"Model_zoo/\", \"Path to vgg model mat\")\n",
    "tf.flags.DEFINE_bool('debug', \"False\", \"Debug mode: True/ False\")\n",
    "tf.flags.DEFINE_string('mode', \"train\", \"Mode train/ test\")\n",
    "tf.flags.DEFINE_bool('restore_model', \"False\", \"Restore Model: True/ False\")\n",
    "\n",
    "MODEL_URL = 'http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat'\n",
    "\n",
    "MAX_ITERATION = int(1e5 + 1)\n",
    "IMAGE_SIZE = 256\n",
    "ADVERSARIAL_LOSS_WEIGHT = 1e-3\n",
    "\n",
    "def vgg_net(weights, image):\n",
    "    layers = (\n",
    "        # 'conv1_1', 'relu1_1',\n",
    "        'conv1_2', 'relu1_2', 'pool1',\n",
    "\n",
    "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "\n",
    "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "\n",
    "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "\n",
    "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "        'relu5_3', 'conv5_4', 'relu5_4'\n",
    "    )\n",
    "\n",
    "    net = {}\n",
    "    current = image\n",
    "    for i, name in enumerate(layers):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias = weights[i + 2][0][0][0][0]\n",
    "            # matconvnet: weights are [width, height, in_channels, out_channels]\n",
    "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "            kernels = utils.get_variable(np.transpose(kernels, (1, 0, 2, 3)), name=name + \"_w\")\n",
    "            bias = utils.get_variable(bias.reshape(-1), name=name + \"_b\")\n",
    "            current = utils.conv2d_basic(current, kernels, bias)\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current, name=name)\n",
    "            if FLAGS.debug:\n",
    "                utils.add_activation_summary(current)\n",
    "        elif kind == 'pool':\n",
    "            current = utils.avg_pool_2x2(current)\n",
    "        net[name] = current\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def generator(images, train_phase):\n",
    "    print(\"setting up vgg initialized conv layers ...\")\n",
    "    model_data = utils.get_model_data(FLAGS.model_dir, MODEL_URL)\n",
    "\n",
    "    weights = np.squeeze(model_data['layers'])\n",
    "\n",
    "    with tf.variable_scope(\"generator\") as scope:\n",
    "        W0 = utils.weight_variable([3, 3, 1, 64], name=\"W0\")\n",
    "        b0 = utils.bias_variable([64], name=\"b0\")\n",
    "        conv0 = utils.conv2d_basic(images, W0, b0)\n",
    "        hrelu0 = tf.nn.relu(conv0, name=\"relu\")\n",
    "\n",
    "        image_net = vgg_net(weights, hrelu0)\n",
    "        vgg_final_layer = image_net[\"relu5_3\"]\n",
    "\n",
    "        pool5 = utils.max_pool_2x2(vgg_final_layer)\n",
    "\n",
    "        # now to upscale to actual image size\n",
    "        deconv_shape1 = image_net[\"pool4\"].get_shape()\n",
    "        W_t1 = utils.weight_variable([4, 4, deconv_shape1[3].value, pool5.get_shape()[3].value], name=\"W_t1\")\n",
    "        b_t1 = utils.bias_variable([deconv_shape1[3].value], name=\"b_t1\")\n",
    "        conv_t1 = utils.conv2d_transpose_strided(pool5, W_t1, b_t1, output_shape=tf.shape(image_net[\"pool4\"]))\n",
    "        fuse_1 = tf.add(conv_t1, image_net[\"pool4\"], name=\"fuse_1\")\n",
    "\n",
    "        deconv_shape2 = image_net[\"pool3\"].get_shape()\n",
    "        W_t2 = utils.weight_variable([4, 4, deconv_shape2[3].value, deconv_shape1[3].value], name=\"W_t2\")\n",
    "        b_t2 = utils.bias_variable([deconv_shape2[3].value], name=\"b_t2\")\n",
    "        conv_t2 = utils.conv2d_transpose_strided(fuse_1, W_t2, b_t2, output_shape=tf.shape(image_net[\"pool3\"]))\n",
    "        fuse_2 = tf.add(conv_t2, image_net[\"pool3\"], name=\"fuse_2\")\n",
    "\n",
    "        shape = tf.shape(images)\n",
    "        deconv_shape3 = tf.stack([shape[0], shape[1], shape[2], 2])\n",
    "        W_t3 = utils.weight_variable([16, 16, 2, deconv_shape2[3].value], name=\"W_t3\")\n",
    "        b_t3 = utils.bias_variable([2], name=\"b_t3\")\n",
    "        pred = utils.conv2d_transpose_strided(fuse_2, W_t3, b_t3, output_shape=deconv_shape3, stride=8)\n",
    "\n",
    "    return tf.concat(axis=3, values=[images, pred], name=\"pred_image\")\n",
    "\n",
    "\n",
    "def train(loss, var_list):\n",
    "    optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate, beta1=FLAGS.beta1)\n",
    "    grads = optimizer.compute_gradients(loss, var_list=var_list)\n",
    "    for grad, var in grads:\n",
    "        utils.add_gradient_summary(grad, var)\n",
    "    return optimizer.apply_gradients(grads)\n",
    "\n",
    "\n",
    "def transform(dir):\n",
    "    images = []\n",
    "    for filename in glob.iglob(dir+'*',recursive=True):\n",
    "        print(filename)\n",
    "        image = skimage.io.imread(filename)\n",
    "        resize_image = skimage.transform.resize( image, [224, 224] , mode='constant')\n",
    "        resize_image = color.rgb2lab(resize_image)\n",
    "        images.append(np.array(resize_image))\n",
    "    images = np.array(images)\n",
    "    return np.expand_dims(images[:, :, :, 0], axis=3), images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up network...\n",
      "setting up vgg initialized conv layers ...\n",
      "Setting up session\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-62400\n",
      "Model restored...\n",
      "Reading image dataset...\n",
      "Found pickle file!\n",
      "Training: 2569, Validation: 734, Test: 367\n",
      "Initializing Batch Dataset Reader...\n",
      "{'resize': True, 'resize_size': 256, 'color': 'LAB'}\n",
      "(734, 256, 256, 3)\n",
      "Current batch loss =  1.16411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyrus/anaconda2/envs/py36/lib/python3.6/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logs/image_pred/gt0.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5d3b7a78fe66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5d3b7a78fe66>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartIdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartIdx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gt\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pred\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Images saved on validation run ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/colorization/TensorflowUtils.py\u001b[0m in \u001b[0;36msave_image\u001b[0;34m(image, save_dir, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \"\"\"\n\u001b[1;32m     55\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlab2rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_low_contrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s is a low contrast image'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imsave'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                                (plugin, kind))\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, format_str, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndarray_to_pil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1925\u001b[0m             \u001b[0;31m# Open also for reading (\"+\"), because TIFF save_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;31m# writer needs to go back and edit the written data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1927\u001b[0;31m             \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'logs/image_pred/gt0.png'"
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    print(\"Setting up network...\")\n",
    "    train_phase = tf.placeholder(tf.bool, name=\"train_phase\")\n",
    "    images = tf.placeholder(tf.float32, shape=[None, None, None, 1], name='L_image')\n",
    "    lab_images = tf.placeholder(tf.float32, shape=[None, None, None, 3], name=\"LAB_image\")\n",
    "\n",
    "    pred_image = generator(images, train_phase)\n",
    "\n",
    "    gen_loss_mse = tf.reduce_mean(2 * tf.nn.l2_loss(pred_image - lab_images)) / (IMAGE_SIZE * IMAGE_SIZE * 100 * 100)\n",
    "    tf.summary.scalar(\"Generator_loss_MSE\", gen_loss_mse)\n",
    "\n",
    "    train_variables = tf.trainable_variables()\n",
    "    for v in train_variables:\n",
    "        utils.add_to_regularization_and_summary(var=v)\n",
    "\n",
    "    train_op = train(gen_loss_mse, train_variables)\n",
    "    \n",
    "    print(\"Setting up session\")\n",
    "    sess = tf.Session()\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    saver = tf.train.Saver()\n",
    "    summary_writer = tf.summary.FileWriter(FLAGS.logs_dir, sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(FLAGS.model_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(\"Model restored...\")\n",
    "    else:\n",
    "        print(\"Model is not found\")\n",
    "        return\n",
    "    \n",
    "    print(\"Reading demo image ...\")\n",
    "    l_image, color_images = transform(FLAGS.data_dir)\n",
    "    \n",
    "    \n",
    "    feed_dict = {images: l_image, lab_images: color_images, train_phase: False}\n",
    "    save_dir = FLAGS.data_dir\n",
    "    pred = sess.run(pred_image, feed_dict=feed_dict)\n",
    "        \n",
    "    for itr in range(color_images.shape[0]):\n",
    "        #utils.save_image(color_images[idx], save_dir, \"gt\" + str(itr))\n",
    "        utils.save_image(pred[itr].astype(np.float64), save_dir, \"pred\" + str(itr))\n",
    "    print(\"--- Images saved on demo run ---\")\n",
    "   \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
